<h1 align="center">ğŸ‘‹ OlÃ¡, eu sou <strong>Luis Camargo</strong></h1>
<h3 align="center">Especialista em LogÃ­stica e Engenharia de Dados</h3>

<p align="center">
  <a href="https://www.linkedin.com/in/luisespecialista/" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <a href="mailto:especialista.luiscamargo@gmail.com">
    <img src="https://img.shields.io/badge/Email-especialista.luiscamargo%40gmail.com-red?logo=gmail&logoColor=white" alt="Email"/>
  </a>
  <a href="https://wa.me/5511940880735">
    <img src="https://img.shields.io/badge/WhatsApp-Contato-brightgreen?logo=whatsapp&logoColor=white" alt="WhatsApp"/>
  </a>
</p>

---

## ğŸš€ Logistic Data Lake â€” DemonstraÃ§Ã£o Interna

Este projeto Ã© uma **demonstraÃ§Ã£o corporativa de Data Lake**, baseado na arquitetura **Medallion (RAW â†’ BRONZE â†’ SILVER â†’ GOLD)**, totalmente executÃ¡vel em ambiente local com:

- **Airflow** (orquestraÃ§Ã£o e automaÃ§Ã£o de pipelines)
- **PostgreSQL** (metadados do Airflow + camada GOLD)
- **MinIO** (armazenamento RAW, BRONZE e SILVER em Parquet)
- **Soda Core** (monitoramento e validaÃ§Ã£o de qualidade de dados)
- **SQL puro e Python** para mÃ¡xima performance

> âš ï¸ Este repositÃ³rio Ã© **privado** e destinado apenas a demonstraÃ§Ã£o interna. NÃ£o deve ser compartilhado publicamente.

---

## ğŸ§© Objetivo

Mostrar **como projetar, validar e executar pipelines de Data Lake** corporativos, permitindo:

- IngestÃ£o incremental de dados brutos
- Processamento e padronizaÃ§Ã£o em Parquet
- Monitoramento de qualidade de dados com Soda Core
- TransformaÃ§Ãµes e agregaÃ§Ãµes em SQL puro
- OrquestraÃ§Ã£o de fluxo de dados com Airflow

---

## ğŸ—ï¸ Arquitetura

