<h1 align="center">ğŸ‘‹ OlÃ¡, eu sou <strong>Luis Camargo</strong></h1>
<h3 align="center">Especialista em LogÃ­stica e Engenharia de Dados</h3>

<p align="center">
  <a href="https://www.linkedin.com/in/luisespecialista/" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <a href="mailto:especialista.luiscamargo@gmail.com">
    <img src="https://img.shields.io/badge/Email-especialista.luiscamargo%40gmail.com-red?logo=gmail&logoColor=white" alt="Email"/>
  </a>
  <a href="https://wa.me/5511940880735">
    <img src="https://img.shields.io/badge/WhatsApp-Contato-brightgreen?logo=whatsapp&logoColor=white" alt="WhatsApp"/>
  </a>
</p>

---

## ğŸš€ Logistic Data Lake â€” DemonstraÃ§Ã£o Interna

Este projeto Ã© uma **demonstraÃ§Ã£o corporativa de Data Lake**, baseado na arquitetura **Medallion (RAW â†’ BRONZE â†’ SILVER â†’ GOLD)**, totalmente executÃ¡vel em ambiente local com:

- **Airflow** (orquestraÃ§Ã£o e automaÃ§Ã£o de pipelines)
- **PostgreSQL** (metadados do Airflow + camada GOLD)
- **MinIO** (armazenamento RAW, BRONZE e SILVER em Parquet)
- **Soda Core** (monitoramento e validaÃ§Ã£o de qualidade de dados)
- **SQL puro e Python** para mÃ¡xima performance

> âš ï¸ Este repositÃ³rio Ã© **privado** e destinado apenas a demonstraÃ§Ã£o interna. NÃ£o deve ser compartilhado publicamente.

---

## ğŸ§© Objetivo

Mostrar **como projetar, validar e executar pipelines de Data Lake** corporativos, permitindo:

- IngestÃ£o incremental de dados brutos
- Processamento e padronizaÃ§Ã£o em Parquet
- Monitoramento de qualidade de dados com Soda Core
- TransformaÃ§Ãµes e agregaÃ§Ãµes em SQL puro
- OrquestraÃ§Ã£o de fluxo de dados com Airflow

---

## ğŸ—ï¸ Arquitetura
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   RAW      â”‚  â† Dados brutos (CSV, JSON, APIs, etc.)
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
     IngestÃ£o (Airflow + Python)
            â”‚
      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚  BRONZE    â”‚  â† PadronizaÃ§Ã£o, formataÃ§Ã£o, Parquet
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
     ValidaÃ§Ã£o (Soda Core)
            â”‚
      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚  SILVER    â”‚  â† Dados refinados e prontos para modelagem
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
     AgregaÃ§Ãµes / SQL puro (PostgreSQL)
            â”‚
      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
      â”‚   GOLD     â”‚  â† Data Warehouse analÃ­tico
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

      
---

## âš™ï¸ Stack TÃ©cnica
Componente,FunÃ§Ã£o Principal,Detalhes TÃ©cnicos
Apache Airflow 2.7+,OrquestraÃ§Ã£o de Pipelines,LocalExecutor com DAGs modulares
PostgreSQL,Metadados e Camada GOLD,Consultas SQL otimizadas para DW
MinIO (S3 local),Armazenamento do Data Lake,"RAW, BRONZE, SILVER via s3fs e boto3"
Parquet + PyArrow,Formato de Dados,Alta performance e compressÃ£o
Soda Core,Data Quality,DefiniÃ§Ã£o de regras e monitoramento
Python,ETL e LÃ³gica de NegÃ³cio,"Pandas, PyArrow, Faker, Boto3"

## ğŸ“‚ Estrutura de Pastas

ğŸ“¦ Logistic_Datalake
â”£ ğŸ“‚ dags/ â†’ DAGs Airflow (RAW â†’ GOLD + QA)
â”£ ğŸ“‚ scripts/ â†’ FunÃ§Ãµes auxiliares e ETLs
â”£ ğŸ“‚ data/ â†’ Dados particionados por camada (Parquet)
â”£ ğŸ“‚ soda/ â†’ ConfiguraÃ§Ã£o e scans do Soda Core
â”£ ğŸ“‚ logs/ â†’ Logs do Airflow (nÃ£o versionados)
â”£ ğŸ“œ docker-compose.yml â†’ Infraestrutura local
â”£ ğŸ“œ requirements.txt â†’ DependÃªncias Python
â”£ ğŸ“œ .env â†’ VariÃ¡veis de ambiente (credenciais)
â”— ğŸ“œ README.md


---

## ğŸ§° Quick Start (Local)

### 1ï¸âƒ£ â€” Ativar ambiente Python
```powershell
cd "C:\Users\Luis Camargo\Desktop\Logistic_Datalake"
.venv\Scripts\Activate.ps1

2ï¸âƒ£ â€” Subir infraestrutura completa
docker-compose up -d

3ï¸âƒ£ â€” Acessar interfaces
| ServiÃ§o           | URL                                            | Login padrÃ£o                    |
| ----------------- | ---------------------------------------------- | ------------------------------- |
|       Airflow UI  | [http://localhost:8080](http://localhost:8080) | `daxlog123` / `daxlog123`       |
|     MinIO Console | [http://localhost:9001](http://localhost:9001) | `daxlog123` / `daxlog123`       |
|     PostgreSQL    | localhost:5432                                 | DB: `gold_dw` / user: `airflow` |

ğŸ§® Qualidade de Dados â€” Soda Core

ApÃ³s a camada BRONZE, os dados passam por validaÃ§Ãµes automÃ¡ticas de:
ConsistÃªncia de schema
Campos nulos ou duplicados
Regras de negÃ³cio definidas
Executar manualmente scan local: 
soda scan -d postgres -c soda/config.yml soda/checks.yml

ğŸ“ˆ Futuro & ExtensÃµes

IntegraÃ§Ã£o com dbt-core para transformaÃ§Ã£o SQL modular
Deploy remoto em Azure, AWS ou GCP
Streaming de dados (Kafka) e monitoramento (Grafana/Prometheus) 


ğŸ’¼ Autor
<h4>Luis Henrique Camargo â€” Especialista em LogÃ­stica e Engenharia de Dados</h4> <p align="center"> <a href="https://www.linkedin.com/in/luisespecialista/" target="_blank"> <img src="https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white" alt="LinkedIn"/> </a> <a href="mailto:especialista.luiscamargo@gmail.com"> <img src="https://img.shields.io/badge/Email-especialista.luiscamargo%40gmail.com-red?logo=gmail&logoColor=white" alt="Email"/> </a> <a href="https://wa.me/5511940880735"> <img src="https://img.shields.io/badge/WhatsApp-Contato-brightgreen?logo=whatsapp&logoColor=white" alt="WhatsApp"/> </a> </p>

ğŸ’¡ â€œTransformar dados em inteligÃªncia e operaÃ§Ãµes em vantagem competitiva.â€
