# ğŸš€ Data Lake LogÃ­stico â€” DemonstraÃ§Ã£o Interna

Este projeto Ã© uma **demonstraÃ§Ã£o corporativa de Data Lake**, baseada na arquitetura **Medallion (RAW â†’ BRONZE â†’ SILVER â†’ GOLD)**, totalmente apresentada em ambiente local com:

* **Apache Airflow** para orquestraÃ§Ã£o modular;
* **PostgreSQL** (metadados e camada GOLD);
* **MinIO** (armazenamento local S3 para BRONZE e SILVER);
* **Parquet + PyArrow** para formataÃ§Ã£o de dados;
* **Soda Core** para Data Quality e desempenho mÃ¡ximo.

> âš ï¸ **Aviso:** Este repositÃ³rio Ã© **privado** e destinado apenas para demonstraÃ§Ã£o interna. NÃ£o deve ser compartilhado publicamente.

---

## ğŸ¯ Objetivo

Montar como projetos, validar e executar pipelines de Data Lake corporativos, permitindo:

* IngestÃ£o incremental de dados brutos;
* Processamento particionado em Parquet;
* Monitoramento de qualidade de dados com Soda Core;
* Gerenciamento de tabelas de metadados;
* OrquestraÃ§Ã£o de fluxo de dados com Airflow.

---

## ğŸ—ï¸ Arquitetura

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAW    â”‚  â† Dados brutos (CSV, JSON, APIs, etc.)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚
IngestÃ£o (Airflow + Python)
      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚  BRONZE  â”‚  â† PadronizaÃ§Ã£o, formataÃ§Ã£o, Parquet
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚
Limpeza / ValidaÃ§Ã£o (Soda Core)
      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚  SILVER  â”‚  â† Dados refinados, prontos para modelagem
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚
AgregaÃ§Ãµes / SQL puro (PostgreSQL)
      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚   GOLD   â”‚  â† Data Warehouse analÃ­tico
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## âš™ï¸ TÃ©cnica de Pilha

| Componente | FunÃ§Ã£o Principal | Detalhes TÃ©cnicos |
|:-------------|:-----------------|:-------------------|
| **Apache Airflow 2.7+** | OrquestraÃ§Ã£o de Pipelines | LocalExecutor com DAGs modulares |
| **PostgreSQL** | Metadados e Camada GOLD | Consultas SQL otimizadas para DW |
| **MinIO (S3 local)** | Armazenamento do Data Lake | RAW, BRONZE, SILVER via `s3fs` e `boto3` |
| **Parquet + PyArrow** | Formato de Dados | Alta performance e compressÃ£o |
| **Soda Core** | Data Quality | DefiniÃ§Ã£o de regras e monitoramento |
| **Python** | ETL e LÃ³gica de NegÃ³cio | Pandas, PyArrow, Faker, Boto3 |

---

## ğŸ—‚ï¸ Estrutura de Pastas

```
ğŸ“¦ Logistic_Datalake
â”£ ğŸ“‚ dags/ â†’ DAGs do Airflow (RAW, BRONZE, SILVER, GOLD, QA)
â”£ ğŸ“‚ scripts/ â†’ FunÃ§Ãµes auxiliares e scripts de ETL
â”£ ğŸ“‚ data/ â†’ Dados particionados por camada (Parquet)
â”£ ğŸ“‚ soda/ â†’ Arquivos de configuraÃ§Ã£o e scans do Soda Core
â”£ ğŸ“‚ logs/ â†’ Logs do Airflow (Ignorado no Git)
â”£ ğŸ“œ docker-compose.yml â†’ Infraestrutura local completa
â”£ ğŸ“œ requirements.txt â†’ DependÃªncias Python
â”£ ğŸ“œ .env â†’ VariÃ¡veis de ambiente (credenciais, paths)
â”— ğŸ“œ README.md
```

---

## ğŸš€ InÃ­cio RÃ¡pido (Local)

### 1ï¸âƒ£ â€” Ativar ambiente Python

Abra o terminal na pasta raiz do projeto e execute:

```powershell
# Exemplo de ativaÃ§Ã£o de ambiente virtual no PowerShell
cd "C:\Users\Luis Camargo\Desktop\Logistic_Datalake"
.venv\Scripts\Activate.ps1
```

### 2ï¸âƒ£ â€” Subir a infraestrutura completa

Utilize o Docker Compose para iniciar todos os serviÃ§os (Airflow, MinIO, PostgreSQL):

```bash
docker-compose up -d
```

### 3ï¸âƒ£ â€” Acessar as interfaces

| ServiÃ§o | URL | Login PadrÃ£o |
|:---|:---|:---|
| **Airflow UI** | [http://localhost:8080](https://www.google.com/search?q=http://localhost:8080) | `daxlog123` / `daxlog123` |
| **MinIO Console** | [http://localhost:9001](https://www.google.com/search?q=http://localhost:9001) | `daxlog123` / `daxlog123` |
| **PostgreSQL** | `localhost:5432` | DB: `gold_dw` / User: `airflow` |

---

## ğŸ“Š Qualidade de Dados â€” Soda Core

ApÃ³s a ingestÃ£o na camada BRONZE, o Soda Core executa validaÃ§Ãµes automÃ¡ticas:

* ConsistÃªncia de *schema*
* VerificaÃ§Ã£o de campos nulos ou duplicados
* AplicaÃ§Ã£o de regras de negÃ³cio customizadas

**Exemplo de execuÃ§Ã£o manual de scan:**

```bash
soda scan -d postgres -c soda/config.yml soda/checks.yml
```

---

## ğŸ“ˆ Futuro e ExtensÃµes

Este projeto Ã© modular e possui potencial para as seguintes evoluÃ§Ãµes:

* IntegraÃ§Ã£o com **dbt-core** para modelagem SQL moderna na camada SILVER/GOLD.
* *Deploy* remoto em ambientes corporativos (*cloud* como Azure, AWS, GCP).
* AdiÃ§Ã£o de camadas Streaming (**Kafka**) e Monitoring (**Grafana/Prometheus**).

---

## ğŸ“œ LicenÃ§a

MIT License â€” uso interno para demonstraÃ§Ã£o e aprendizado.
