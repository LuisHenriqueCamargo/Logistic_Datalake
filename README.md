# ğŸš€ Data Lake LogÃ­stico â€” DemonstraÃ§Ã£o Interna

Este projeto Ã© uma **demonstraÃ§Ã£o corporativa de Data Lake**, baseada na arquitetura **Medallion (RAW â†’ BRONZE â†’ SILVER â†’ GOLD)**, totalmente apresentada em ambiente local com:

* **Apache Airflow** para orquestraÃ§Ã£o modular;
* **PostgreSQL** (metadados e camada GOLD);
* **MinIO** (armazenamento local S3 para BRONZE e SILVER);
* **Parquet + PyArrow** para formataÃ§Ã£o de dados;
* **Soda Core** para Data Quality e desempenho mÃ¡ximo.

> âš ï¸ **Aviso:** Este repositÃ³rio Ã© **privado** e destinado apenas para demonstraÃ§Ã£o interna. NÃ£o deve ser compartilhado publicamente.

---

## ğŸ¯ Objetivo

Montar como projetos, validar e executar pipelines de Data Lake corporativos, permitindo:

* IngestÃ£o incremental de dados brutos;
* Processamento particionado em Parquet;
* Monitoramento de qualidade de dados com Soda Core;
* Gerenciamento de tabelas de metadados;
* OrquestraÃ§Ã£o de fluxo de dados com Airflow.

---

## ğŸ—ï¸ Arquitetura



 ![1732023052836](https://github.com/user-attachments/assets/7e301022-c502-4104-948f-c9c55eb3d189)



## âš™ï¸ Provas Visuais da ExecuÃ§Ã£o
OrquestraÃ§Ã£o e Pipeline (Airflow)

 O Airflow gerencia e automatiza a execuÃ§Ã£o de cada estÃ¡gio (RAW, BRONZE, SILVER, GOLD), garantindo a confiabilidade do pipeline.
<img width="1888" height="971" alt="image" src="https://github.com/user-attachments/assets/90967efb-d96a-4fa7-87ee-099e12750baf" /> 

Data Lake Storage (MinIO)

UtilizaÃ§Ã£o do MinIO para simular um S3, garantindo o armazenamento imutÃ¡vel e particionado das camadas BRONZE e SILVER.
<img width="1913" height="985" alt="image" src="https://github.com/user-attachments/assets/dd1ad11c-8885-463d-bd92-727170b43511" /> 

Resultado Final (Camada GOLD)

A camada GOLD contÃ©m os dados modelados e agregados, prontos para consumo por ferramentas de BI, comprovando a entrega final do projeto.
<img width="1918" height="1027" alt="image" src="https://github.com/user-attachments/assets/59df0de0-eabf-44d3-9477-edbd78e6104a" />




## âš™ï¸ TÃ©cnica de Pilha

| Componente | FunÃ§Ã£o Principal | Detalhes TÃ©cnicos |
|:-------------|:-----------------|:-------------------|
| **Apache Airflow 2.7+** | OrquestraÃ§Ã£o de Pipelines | LocalExecutor com DAGs modulares |
| **PostgreSQL** | Metadados e Camada GOLD | Consultas SQL otimizadas para DW |
| **MinIO (S3 local)** | Armazenamento do Data Lake | RAW, BRONZE, SILVER via `s3fs` e `boto3` |
| **Parquet + PyArrow** | Formato de Dados | Alta performance e compressÃ£o |
| **Soda Core** | Data Quality | DefiniÃ§Ã£o de regras e monitoramento |
| **Python** | ETL e LÃ³gica de NegÃ³cio | Pandas, PyArrow, Faker, Boto3 |

---

## ğŸ—‚ï¸ Estrutura de Pastas

```
ğŸ“¦ Logistic_Datalake
â”£ ğŸ“‚ dags/ â†’ DAGs do Airflow (RAW, BRONZE, SILVER, GOLD, QA)
â”£ ğŸ“‚ scripts/ â†’ FunÃ§Ãµes auxiliares e scripts de ETL
â”£ ğŸ“‚ data/ â†’ Dados particionados por camada (Parquet)
â”£ ğŸ“‚ soda/ â†’ Arquivos de configuraÃ§Ã£o e scans do Soda Core
â”£ ğŸ“‚ logs/ â†’ Logs do Airflow (Ignorado no Git)
â”£ ğŸ“œ docker-compose.yml â†’ Infraestrutura local completa
â”£ ğŸ“œ requirements.txt â†’ DependÃªncias Python
â”£ ğŸ“œ .env â†’ VariÃ¡veis de ambiente (credenciais, paths)
â”— ğŸ“œ README.md
```

---

## ğŸš€ InÃ­cio RÃ¡pido (Local)

### 1ï¸âƒ£ â€” Ativar ambiente Python

Abra o terminal na pasta raiz do projeto e execute:

```powershell
# Exemplo de ativaÃ§Ã£o de ambiente virtual no PowerShell
cd "C:\Users\Luis Camargo\Desktop\Logistic_Datalake"
.venv\Scripts\Activate.ps1
```

### 2ï¸âƒ£ â€” Subir a infraestrutura completa

Utilize o Docker Compose para iniciar todos os serviÃ§os (Airflow, MinIO, PostgreSQL):

```bash
docker-compose up -d

```
<img width="1458" height="350" alt="image" src="https://github.com/user-attachments/assets/2d246e63-6261-4110-84b8-2ab695c6de51" /> 


### 3ï¸âƒ£ â€” Acessar as interfaces

| ServiÃ§o | URL | Login PadrÃ£o |
|:---|:---|:---|
| **Airflow UI** | [http://localhost:8080](https://www.google.com/search?q=http://localhost:8080) | `daxlog123` / `daxlog123` |
| **MinIO Console** | [http://localhost:9001](https://www.google.com/search?q=http://localhost:9001) | `daxlog123` / `daxlog123` |
| **PostgreSQL** | `localhost:5432` | DB: `gold_dw` / User: `airflow` |

--- 



<img width="1908" height="808" alt="image" src="https://github.com/user-attachments/assets/b11731f6-48f3-479d-99a7-b82c87f29f3c" />


## ğŸ“Š Qualidade de Dados â€” Soda Core

ApÃ³s a ingestÃ£o na camada BRONZE, o Soda Core executa validaÃ§Ãµes automÃ¡ticas:

* ConsistÃªncia de *schema*
* VerificaÃ§Ã£o de campos nulos ou duplicados
* AplicaÃ§Ã£o de regras de negÃ³cio customizadas

**Exemplo de execuÃ§Ã£o manual de scan:**

```bash
soda scan -d postgres -c soda/config.yml soda/checks.yml
```

---

## ğŸ“ˆ Futuro e ExtensÃµes

Este projeto Ã© modular e possui potencial para as seguintes evoluÃ§Ãµes:

* IntegraÃ§Ã£o com **dbt-core** para modelagem SQL moderna na camada SILVER/GOLD.
* *Deploy* remoto em ambientes corporativos (*cloud* como Azure, AWS, GCP).
* AdiÃ§Ã£o de camadas Streaming (**Kafka**) e Monitoring (**Grafana/Prometheus**).

---

## ğŸ“œ LicenÃ§a

MIT License â€” uso interno para demonstraÃ§Ã£o e aprendizado.
